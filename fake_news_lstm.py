# -*- coding: utf-8 -*-
"""Fake_News_LSTM.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1IGzoFEoMDjU6Cwe5iZ7ARB4AABhDT8i2

Fake news classifier using LSTM
"""

import pandas as pd

data=pd.read_csv("/content/drive/My Drive/Deep learning/train.csv")

data.head()

df=data.dropna() #Dropping NaN values

x=df.drop('label',axis=1)

y=df['label']

x.shape

y.shape

import tensorflow as tf

tf.__version__

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.layers import LSTM
from tensorflow.keras.layers import Embedding
from tensorflow.keras.preprocessing.text import one_hot
from tensorflow.keras.preprocessing.sequence import pad_sequences

voc_size=5000

"""One Hot Encoding"""

message=x.copy()

message['title'][0]

message.reset_index(inplace=True)

import nltk
import re

from nltk.corpus import stopwords

nltk.download('stopwords')

"""Data Preprocessing"""

from nltk.stem.porter import PorterStemmer
ps=PorterStemmer()
corpus=[]
for i in range(0,len(message)):
  print(i)
  review=re.sub('[^a-zA-Z]',' ',message['title'][i])
  review=review.lower()
  review=review.split()
  review=[ps.stem(word) for word in review if not word in stopwords.words('english')]
  review=' '.join(review)
  corpus.append(review)

corpus

one_hot_rep=[one_hot(words,voc_size) for words in corpus]

print(one_hot_rep)

"""Embedding Representation"""

sen_length=20
emb_docs=pad_sequences(one_hot_rep,padding='pre',maxlen=sen_length)
print(emb_docs)

"""Model_Building"""

embedding_vector_features=40
model=Sequential()
model.add(Embedding(voc_size,embedding_vector_features,input_length=sen_length))
model.add(LSTM(100))
model.add(Dense(1,activation='sigmoid'))
model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])
print(model.summary())

import numpy as np
X_final=np.array(emb_docs)
y_final=np.array(y)

X_final.shape,y_final.shape

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X_final, y_final, test_size=0.33, random_state=42)

#Model Training

model.fit(X_train,y_train,validation_data=(X_test,y_test),batch_size=64,epochs=10)

#Performance measure:
y_pred=model.predict_classes(X_test)

from sklearn.metrics import classification_report,confusion_matrix
print(classification_report(y_test,y_pred))

print(confusion_matrix(y_test,y_pred))

from sklearn.metrics import accuracy_score
print(accuracy_score(y_test,y_pred))

"""Adding Droput Layer"""

from tensorflow.keras.layers import Dropout
## Creating model
embedding_vector_features=40
model1=Sequential()
model1.add(Embedding(voc_size,embedding_vector_features,input_length=sen_length))
model1.add(Dropout(0.3))
model1.add(LSTM(100))
model1.add(Dropout(0.3))
model1.add(Dense(1,activation='sigmoid'))
model1.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])

model1.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=10,batch_size=64)

y_pred1=model1.predict_classes(X_test)

from sklearn.metrics import classification_report,confusion_matrix,accuracy_score
print(classification_report(y_test,y_pred1))
print(confusion_matrix(y_test,y_pred1))
print(accuracy_score(y_test,y_pred1))

